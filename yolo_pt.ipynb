{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import skimage\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as FT\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "seed = 123\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "torch.manual_seed(seed)\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_config = [\n",
    "    #Tuple: (Kernel_size, number of filters, strides, padding)\n",
    "    (7, 64, 2, 3),\n",
    "    #\"M\" = Max Pool layer\n",
    "    \"M\",\n",
    "    (3, 192, 1, 1),\n",
    "    \"M\",\n",
    "    (1, 128, 1, 0),\n",
    "    (3, 256, 1, 1),\n",
    "    (1, 256, 1, 0),\n",
    "    (3, 512, 1, 1),\n",
    "    \"M\",\n",
    "    #List: [(tuple), (tuple), how many time to repeat]\n",
    "    [(1, 256, 1, 0), (3, 512, 1, 1), 4],\n",
    "    (1, 512, 1, 0),\n",
    "    (3, 1024, 1, 1),\n",
    "    \"M\",\n",
    "    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 2, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "    #Doesnt include fc layers\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.leakyrelu(self.batchnorm(self.conv(x)))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture_config[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(architecture_config[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNBlock(\n",
       "  (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "CNNBlock(3,64, kernel_size=7,stride=2,padding=3)\n",
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): CNNBlock(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (1): CNNBlock(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = []\n",
    "layers += [\n",
    "    CNNBlock(3,64, kernel_size=7,stride=2,padding=3),\n",
    "    CNNBlock(3,64, kernel_size=7,stride=2,padding=3),\n",
    "]\n",
    "def fu(*args):\n",
    "    print(args)\n",
    "\n",
    "nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class YoloV1(nn.Module):\n",
    "    def __init__(self, in_channels=3, **kwargs):\n",
    "        super(YoloV1, self).__init__()\n",
    "        self.architecture = architecture_config\n",
    "        self.in_channels = in_channels\n",
    "        self.darknet = self._create_conv_layers(self.architecture)\n",
    "        self.fcs = self._create_fcs(**kwargs)\n",
    "\n",
    "    def _create_fcs(self, split_size, num_boxes, num_classes):\n",
    "        S, B, C = split_size, num_boxes, num_classes\n",
    "        return nn.Sequential(nn.Flatten(),nn.Linear(1024 * S * S,496), nn.Dropout(0.0), nn.LeakyReLU(0.1),nn.Linear(496, S * S * (C + B *5)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.darknet(x)\n",
    "        return self.fcs(torch.flatten(x,start_dim=1))\n",
    "    \n",
    "    def _create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == tuple:\n",
    "                layers += [CNNBlock(in_channels, x[1], kernel_size=x[0],stride=x[2], padding=x[3])]\n",
    "                in_channels = x[1]\n",
    "            elif type(x) == str:\n",
    "                layers += [nn.MaxPool2d(kernel_size=2,stride=2)]\n",
    "            elif type(x) == list:\n",
    "                conv1 = x[0]\n",
    "                conv2 = x[1]\n",
    "                repeats = x[2]\n",
    "                #repeats = 4\n",
    "                for _ in range(repeats):\n",
    "                    # in_channels = 64 for the first time\n",
    "                    # conv1 = [1, 256, 1, 0] for the first time\n",
    "                    layers += [CNNBlock(in_channels,conv1[1],kernel_size=conv1[0],stride=conv1[2],padding=conv1[3])]\n",
    "                    # conv1[1] = 256 for the first time\n",
    "                    # conv2 = [3, 512, 1, 1] for the first time\n",
    "                    layers += [CNNBlock(conv1[1],conv2[1],kernel_size=conv2[0],stride=conv2[2],padding=conv2[3])]\n",
    "                    in_channels = conv2[1]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darknet.0.conv.weight\n",
      "torch.Size([64, 3, 7, 7])\n",
      "darknet.0.batchnorm.weight\n",
      "torch.Size([64])\n",
      "darknet.0.batchnorm.bias\n",
      "torch.Size([64])\n",
      "darknet.0.batchnorm.running_mean\n",
      "torch.Size([64])\n",
      "darknet.0.batchnorm.running_var\n",
      "torch.Size([64])\n",
      "darknet.0.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.2.conv.weight\n",
      "torch.Size([192, 64, 3, 3])\n",
      "darknet.2.batchnorm.weight\n",
      "torch.Size([192])\n",
      "darknet.2.batchnorm.bias\n",
      "torch.Size([192])\n",
      "darknet.2.batchnorm.running_mean\n",
      "torch.Size([192])\n",
      "darknet.2.batchnorm.running_var\n",
      "torch.Size([192])\n",
      "darknet.2.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.4.conv.weight\n",
      "torch.Size([128, 192, 1, 1])\n",
      "darknet.4.batchnorm.weight\n",
      "torch.Size([128])\n",
      "darknet.4.batchnorm.bias\n",
      "torch.Size([128])\n",
      "darknet.4.batchnorm.running_mean\n",
      "torch.Size([128])\n",
      "darknet.4.batchnorm.running_var\n",
      "torch.Size([128])\n",
      "darknet.4.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.5.conv.weight\n",
      "torch.Size([256, 128, 3, 3])\n",
      "darknet.5.batchnorm.weight\n",
      "torch.Size([256])\n",
      "darknet.5.batchnorm.bias\n",
      "torch.Size([256])\n",
      "darknet.5.batchnorm.running_mean\n",
      "torch.Size([256])\n",
      "darknet.5.batchnorm.running_var\n",
      "torch.Size([256])\n",
      "darknet.5.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.6.conv.weight\n",
      "torch.Size([256, 256, 1, 1])\n",
      "darknet.6.batchnorm.weight\n",
      "torch.Size([256])\n",
      "darknet.6.batchnorm.bias\n",
      "torch.Size([256])\n",
      "darknet.6.batchnorm.running_mean\n",
      "torch.Size([256])\n",
      "darknet.6.batchnorm.running_var\n",
      "torch.Size([256])\n",
      "darknet.6.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.7.conv.weight\n",
      "torch.Size([512, 256, 3, 3])\n",
      "darknet.7.batchnorm.weight\n",
      "torch.Size([512])\n",
      "darknet.7.batchnorm.bias\n",
      "torch.Size([512])\n",
      "darknet.7.batchnorm.running_mean\n",
      "torch.Size([512])\n",
      "darknet.7.batchnorm.running_var\n",
      "torch.Size([512])\n",
      "darknet.7.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.9.conv.weight\n",
      "torch.Size([256, 512, 1, 1])\n",
      "darknet.9.batchnorm.weight\n",
      "torch.Size([256])\n",
      "darknet.9.batchnorm.bias\n",
      "torch.Size([256])\n",
      "darknet.9.batchnorm.running_mean\n",
      "torch.Size([256])\n",
      "darknet.9.batchnorm.running_var\n",
      "torch.Size([256])\n",
      "darknet.9.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.10.conv.weight\n",
      "torch.Size([512, 256, 3, 3])\n",
      "darknet.10.batchnorm.weight\n",
      "torch.Size([512])\n",
      "darknet.10.batchnorm.bias\n",
      "torch.Size([512])\n",
      "darknet.10.batchnorm.running_mean\n",
      "torch.Size([512])\n",
      "darknet.10.batchnorm.running_var\n",
      "torch.Size([512])\n",
      "darknet.10.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.11.conv.weight\n",
      "torch.Size([256, 512, 1, 1])\n",
      "darknet.11.batchnorm.weight\n",
      "torch.Size([256])\n",
      "darknet.11.batchnorm.bias\n",
      "torch.Size([256])\n",
      "darknet.11.batchnorm.running_mean\n",
      "torch.Size([256])\n",
      "darknet.11.batchnorm.running_var\n",
      "torch.Size([256])\n",
      "darknet.11.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.12.conv.weight\n",
      "torch.Size([512, 256, 3, 3])\n",
      "darknet.12.batchnorm.weight\n",
      "torch.Size([512])\n",
      "darknet.12.batchnorm.bias\n",
      "torch.Size([512])\n",
      "darknet.12.batchnorm.running_mean\n",
      "torch.Size([512])\n",
      "darknet.12.batchnorm.running_var\n",
      "torch.Size([512])\n",
      "darknet.12.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.13.conv.weight\n",
      "torch.Size([256, 512, 1, 1])\n",
      "darknet.13.batchnorm.weight\n",
      "torch.Size([256])\n",
      "darknet.13.batchnorm.bias\n",
      "torch.Size([256])\n",
      "darknet.13.batchnorm.running_mean\n",
      "torch.Size([256])\n",
      "darknet.13.batchnorm.running_var\n",
      "torch.Size([256])\n",
      "darknet.13.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.14.conv.weight\n",
      "torch.Size([512, 256, 3, 3])\n",
      "darknet.14.batchnorm.weight\n",
      "torch.Size([512])\n",
      "darknet.14.batchnorm.bias\n",
      "torch.Size([512])\n",
      "darknet.14.batchnorm.running_mean\n",
      "torch.Size([512])\n",
      "darknet.14.batchnorm.running_var\n",
      "torch.Size([512])\n",
      "darknet.14.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.15.conv.weight\n",
      "torch.Size([256, 512, 1, 1])\n",
      "darknet.15.batchnorm.weight\n",
      "torch.Size([256])\n",
      "darknet.15.batchnorm.bias\n",
      "torch.Size([256])\n",
      "darknet.15.batchnorm.running_mean\n",
      "torch.Size([256])\n",
      "darknet.15.batchnorm.running_var\n",
      "torch.Size([256])\n",
      "darknet.15.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.16.conv.weight\n",
      "torch.Size([512, 256, 3, 3])\n",
      "darknet.16.batchnorm.weight\n",
      "torch.Size([512])\n",
      "darknet.16.batchnorm.bias\n",
      "torch.Size([512])\n",
      "darknet.16.batchnorm.running_mean\n",
      "torch.Size([512])\n",
      "darknet.16.batchnorm.running_var\n",
      "torch.Size([512])\n",
      "darknet.16.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.17.conv.weight\n",
      "torch.Size([512, 512, 1, 1])\n",
      "darknet.17.batchnorm.weight\n",
      "torch.Size([512])\n",
      "darknet.17.batchnorm.bias\n",
      "torch.Size([512])\n",
      "darknet.17.batchnorm.running_mean\n",
      "torch.Size([512])\n",
      "darknet.17.batchnorm.running_var\n",
      "torch.Size([512])\n",
      "darknet.17.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.18.conv.weight\n",
      "torch.Size([1024, 512, 3, 3])\n",
      "darknet.18.batchnorm.weight\n",
      "torch.Size([1024])\n",
      "darknet.18.batchnorm.bias\n",
      "torch.Size([1024])\n",
      "darknet.18.batchnorm.running_mean\n",
      "torch.Size([1024])\n",
      "darknet.18.batchnorm.running_var\n",
      "torch.Size([1024])\n",
      "darknet.18.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.20.conv.weight\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "darknet.20.batchnorm.weight\n",
      "torch.Size([512])\n",
      "darknet.20.batchnorm.bias\n",
      "torch.Size([512])\n",
      "darknet.20.batchnorm.running_mean\n",
      "torch.Size([512])\n",
      "darknet.20.batchnorm.running_var\n",
      "torch.Size([512])\n",
      "darknet.20.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.21.conv.weight\n",
      "torch.Size([1024, 512, 3, 3])\n",
      "darknet.21.batchnorm.weight\n",
      "torch.Size([1024])\n",
      "darknet.21.batchnorm.bias\n",
      "torch.Size([1024])\n",
      "darknet.21.batchnorm.running_mean\n",
      "torch.Size([1024])\n",
      "darknet.21.batchnorm.running_var\n",
      "torch.Size([1024])\n",
      "darknet.21.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.22.conv.weight\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "darknet.22.batchnorm.weight\n",
      "torch.Size([512])\n",
      "darknet.22.batchnorm.bias\n",
      "torch.Size([512])\n",
      "darknet.22.batchnorm.running_mean\n",
      "torch.Size([512])\n",
      "darknet.22.batchnorm.running_var\n",
      "torch.Size([512])\n",
      "darknet.22.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.23.conv.weight\n",
      "torch.Size([1024, 512, 3, 3])\n",
      "darknet.23.batchnorm.weight\n",
      "torch.Size([1024])\n",
      "darknet.23.batchnorm.bias\n",
      "torch.Size([1024])\n",
      "darknet.23.batchnorm.running_mean\n",
      "torch.Size([1024])\n",
      "darknet.23.batchnorm.running_var\n",
      "torch.Size([1024])\n",
      "darknet.23.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.24.conv.weight\n",
      "torch.Size([1024, 1024, 3, 3])\n",
      "darknet.24.batchnorm.weight\n",
      "torch.Size([1024])\n",
      "darknet.24.batchnorm.bias\n",
      "torch.Size([1024])\n",
      "darknet.24.batchnorm.running_mean\n",
      "torch.Size([1024])\n",
      "darknet.24.batchnorm.running_var\n",
      "torch.Size([1024])\n",
      "darknet.24.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.25.conv.weight\n",
      "torch.Size([1024, 1024, 3, 3])\n",
      "darknet.25.batchnorm.weight\n",
      "torch.Size([1024])\n",
      "darknet.25.batchnorm.bias\n",
      "torch.Size([1024])\n",
      "darknet.25.batchnorm.running_mean\n",
      "torch.Size([1024])\n",
      "darknet.25.batchnorm.running_var\n",
      "torch.Size([1024])\n",
      "darknet.25.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.26.conv.weight\n",
      "torch.Size([1024, 1024, 3, 3])\n",
      "darknet.26.batchnorm.weight\n",
      "torch.Size([1024])\n",
      "darknet.26.batchnorm.bias\n",
      "torch.Size([1024])\n",
      "darknet.26.batchnorm.running_mean\n",
      "torch.Size([1024])\n",
      "darknet.26.batchnorm.running_var\n",
      "torch.Size([1024])\n",
      "darknet.26.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "darknet.27.conv.weight\n",
      "torch.Size([1024, 1024, 3, 3])\n",
      "darknet.27.batchnorm.weight\n",
      "torch.Size([1024])\n",
      "darknet.27.batchnorm.bias\n",
      "torch.Size([1024])\n",
      "darknet.27.batchnorm.running_mean\n",
      "torch.Size([1024])\n",
      "darknet.27.batchnorm.running_var\n",
      "torch.Size([1024])\n",
      "darknet.27.batchnorm.num_batches_tracked\n",
      "torch.Size([])\n",
      "fcs.1.weight\n",
      "torch.Size([496, 4096])\n",
      "fcs.1.bias\n",
      "torch.Size([496])\n",
      "fcs.4.weight\n",
      "torch.Size([472, 496])\n",
      "fcs.4.bias\n",
      "torch.Size([472])\n"
     ]
    }
   ],
   "source": [
    "yoloModel = YoloV1(split_size=2,num_boxes=8,num_classes=78).state_dict()\n",
    "yoloKeys = yoloModel.keys()\n",
    "for key in yoloKeys:\n",
    "    print(key)\n",
    "    print(yoloModel[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "## Intersection over Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels,box_format='midpoint'):\n",
    "    \"\"\"\n",
    "    Calculates intersection over union\n",
    "\n",
    "    Parameters:\n",
    "        boxes_preds(tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes are (x,y,w,h) or (x1,y1,x2,y2)\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
